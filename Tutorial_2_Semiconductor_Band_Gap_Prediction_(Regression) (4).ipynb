{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Semiconductor_Band Gap Prediction (Regression)**"
      ],
      "metadata": {
        "id": "n3uup_lwCCNk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Data Loading**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nDzVrGDaMf-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# --- 1. Download & Load Data ---\n",
        "# Download dataset\n",
        "path = kagglehub.dataset_download(\"allanwandia/material-science\")\n",
        "\n",
        "# Find the CSV file in the download folder\n",
        "csv_files = [f for f in os.listdir(path) if f.endswith('.csv')]\n",
        "full_path = os.path.join(path, csv_files[0])\n",
        "\n",
        "df = pd.read_csv(full_path)"
      ],
      "metadata": {
        "id": "QgVmOtC5X-qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Checking data information**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "btEWvsH1NFGx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic command for checking data information**\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "df.info()\n",
        "df.head()\n",
        "df.tail()\n",
        "df.describe()\n",
        "df.columns"
      ],
      "metadata": {
        "id": "tRwo3Wc-NWII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "n9er17sZQnoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check for missing values**"
      ],
      "metadata": {
        "id": "FJDcaYjpNww9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print('Missing values in each column:')\n",
        "print(df.isnull().sum())\n",
        "\n"
      ],
      "metadata": {
        "id": "QP1c4HEbNvMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**If any numeric columns have missing values, fill them with the median**"
      ],
      "metadata": {
        "id": "uAOklIKmQdF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic cleaning: if any numeric columns have missing values, fill them with the median\n",
        "\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "for col in numeric_cols:\n",
        "    if df[col].isnull().sum() > 0:\n",
        "        median_val = df[col].median()\n",
        "        df[col].fillna(median_val, inplace=True)\n",
        "\n",
        "# For any categorical columns with missing values, fill with 'Unknown'\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "for col in categorical_cols:\n",
        "    if df[col].isnull().sum() > 0:\n",
        "        df[col].fillna('Unknown', inplace=True)\n",
        "\n",
        "# Final shape after cleaning\n",
        "print('Data shape after cleaning:', df.shape)"
      ],
      "metadata": {
        "id": "i8Xn24eoQVlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "AgUnvwG-i27h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "jI6B7iRFYx3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Histogram for numeric columns**"
      ],
      "metadata": {
        "id": "HVwdlQPXRS1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Histogram for numeric columns\n",
        "numeric_df = df.select_dtypes(include=[np.number])\n",
        "for col in numeric_df.columns:\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    sns.histplot(df[col], kde=True)\n",
        "    plt.title(f'Histogram of {col}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "TDJSV0Y8Q194"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Correlation Heatmap**"
      ],
      "metadata": {
        "id": "cRN82lLRR9vJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Correlation Heatmap (if there are 4 or more numeric columns)\n",
        "if numeric_df.shape[1] >= 4:\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    corr = numeric_df.corr()\n",
        "    sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm')\n",
        "    plt.title('Correlation Heatmap of Numeric Features')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Bj-xGYjsR8Hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Pair Plot for variables**"
      ],
      "metadata": {
        "id": "iYxuQmDhPxJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(numeric_df)\n",
        "plt.suptitle('Pair Plot for Numeric Features', y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jzRTGwLLD4o-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Modeling**"
      ],
      "metadata": {
        "id": "0pGLD_keZMwP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define target variable and select feature set**\n"
      ],
      "metadata": {
        "id": "AN9u1HcXT284"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Target: Convert True/False to 1/0\n",
        "df_class = df.copy()\n",
        "df_class['target'] = df_class['band_gap']\n",
        "df_class['target'].head()"
      ],
      "metadata": {
        "id": "y0cRJ17EZwep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Features: Physical properties**"
      ],
      "metadata": {
        "id": "zduo_bXiUK59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Features: Physical properties\n",
        "features = ['density', 'formation_energy_per_atom', 'volume', 'n_elements']\n",
        "X = df_class[features]\n",
        "y = df_class['target']"
      ],
      "metadata": {
        "id": "CbJC64RGUPgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split Data**"
      ],
      "metadata": {
        "id": "O7gf4LG6URop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "d4iHwliTUTyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train Single Model**"
      ],
      "metadata": {
        "id": "Vlzbd6YzUWYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate ---\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import numpy as np\n",
        "import joblib\n",
        "model =  RandomForestRegressor(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Display training and testing scores\n",
        "print(f'Training Score: {model.score(X_train, y_train):.4f}')\n",
        "print(f'Testing Score: {model.score(X_test, y_test):.4f}')\n",
        "\n",
        "# Evaluate RMSE for the best model\n",
        "model_pred = model.predict(X_test)\n",
        "model_mae = np.sqrt(mean_absolute_error(y_test, model_pred))\n",
        "print(f'Best Model MAE: {model_mae:.4f}')\n",
        "\n"
      ],
      "metadata": {
        "id": "OLVBLHRWaEz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multiple Modeling**"
      ],
      "metadata": {
        "id": "6lMZjXzIIhMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "# 1. Setup the 6 Contenders\n",
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"K-Nearest Neighbors\": make_pipeline(StandardScaler(), KNeighborsRegressor()),\n",
        "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
        "    \"Gradient Boosting (sklearn)\": GradientBoostingRegressor(random_state=42),\n",
        "    \"Neural Network\": make_pipeline(StandardScaler(), MLPRegressor(hidden_layer_sizes=(100,50), max_iter=1000, random_state=42)),\n",
        "    \"XGBoost\": XGBRegressor(random_state=42)\n",
        "}\n",
        "\n",
        "# List to store results for sorting\n",
        "results_list = []\n",
        "\n",
        "print(\"Training models... please wait.\")\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate metrics\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "    # Store in list\n",
        "    results_list.append({\n",
        "        \"Model\": name,\n",
        "        \"R2\": r2,\n",
        "        \"MAE\": mae\n",
        "    })\n",
        "\n",
        "# --- SORTING LOGIC ---\n",
        "# Sort by R2 Score in Descending order (Highest R2 is best)\n",
        "# If you prefer MAE, change key to x['MAE'] and reverse=False\n",
        "sorted_results = sorted(results_list, key=lambda x: x['R2'], reverse=True)\n",
        "\n",
        "# --- PRINTING ---\n",
        "print(\"\\n\" + \"=\"*55)\n",
        "print(f\"{'Model Name':<30} | {'R2 Score':<10} | {'MAE (eV)':<10}\")\n",
        "print(\"-\" * 55)\n",
        "\n",
        "for res in sorted_results:\n",
        "    print(f\"{res['Model']:<30} | {res['R2']:.4f}     | {res['MAE']:.4f}\")\n",
        "print(\"=\"*55)\n",
        "print(f\"ðŸ† Best Model: {sorted_results[0]['Model']}\")"
      ],
      "metadata": {
        "id": "Btb1yqMTFNJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Save the best model**"
      ],
      "metadata": {
        "id": "wau3rFXOWgi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# 1. Identify the Winner\n",
        "# Grab the name of the model in the first row (since it's sorted by R2 descending)\n",
        "best_model_name = sorted_results[0]['Model']\n",
        "print(f\"\\nðŸ† The Best Model is: {best_model_name}\")\n",
        "\n",
        "# 2. Retrieve the Trained Object\n",
        "# Look up the actual model object from your original 'models' dictionary\n",
        "best_model = models[best_model_name]\n",
        "\n",
        "# 3. Save to Disk\n",
        "filename = 'best_concrete_model_BG.pkl'\n",
        "joblib.dump(best_model, filename)\n",
        "\n",
        "print(f\"âœ… Successfully saved {best_model_name} to '{filename}'\")"
      ],
      "metadata": {
        "id": "HseSnMiUF85_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Get predictions for BOTH sets\n",
        "train_preds = best_model.predict(X_train)\n",
        "test_preds = best_model.predict(X_test)\n",
        "\n",
        "plt.figure(figsize=(9, 9))\n",
        "\n",
        "# 2. Plot Training Data\n",
        "# We use a lower 'alpha' (transparency) because there are usually many more training points\n",
        "plt.scatter(y_train, train_preds, color='tomato', alpha=0.3, label='Training Set (Memorized)')\n",
        "\n",
        "# 3. Plot Test Data\n",
        "plt.scatter(y_test, test_preds, color='skyblue', alpha=0.2, label='Test Set (New Data)')\n",
        "\n",
        "# 4. Draw the \"Perfect Prediction\" Line\n",
        "min_val = min(y.min(), train_preds.min()) # Find the lowest value in the whole dataset\n",
        "max_val = max(y.max(), train_preds.max()) # Find the highest value\n",
        "plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=3, label='Perfect Match')\n",
        "\n",
        "plt.title(\"Overfitting Check: Train vs. Test\")\n",
        "plt.xlabel(\"Actual Strength (MPa)\")\n",
        "plt.ylabel(\"Predicted Strength (MPa)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2ZgfrpbJbYzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Feature importances**"
      ],
      "metadata": {
        "id": "YOvd0gW8VlFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'best_model' now holds the trained RandomForestRegressor\n",
        "# If not, you can load it: best_model = joblib.load('best_materials_model.pkl')\n",
        "# For this example, let's assume you access the trained object from the loop.\n",
        "\n",
        "# --- 1. Get the Importance Scores ---\n",
        "# This is a key feature of all tree-based models!\n",
        "importances = best_model.feature_importances_\n",
        "\n",
        "# 2. Create a clean table\n",
        "# Features list needs to be defined: features = ['density', 'formation_energy_per_atom', 'volume', 'n_elements']\n",
        "features = ['density', 'formation_energy_per_atom', 'volume', 'n_elements'] # Assuming your list\n",
        "\n",
        "feature_table = pd.DataFrame({\n",
        "    'Feature': features,\n",
        "    'Importance': importances\n",
        "})\n",
        "\n",
        "# 3. Sort and print\n",
        "feature_table = feature_table.sort_values(by='Importance', ascending=False)\n",
        "print(\"\\n--- Feature Importance for Random Forest Regressor ---\")\n",
        "print(feature_table)\n",
        "\n",
        "# 4. Visualize it!\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.barh(feature_table['Feature'], feature_table['Importance'], color='skyblue')\n",
        "plt.xlabel('Importance Score (Total = 1.0)')\n",
        "plt.title('Feature Impact on Band Gap Prediction')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NgZTUfobp4wU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "# 1. LOAD the model\n",
        "loaded_model = joblib.load('best_concrete_model_BG.pkl')\n",
        "# Check the feature names expected by the model\n",
        "# (Run this line to see the correct names/order)\n",
        "#print(f\"Feature names expected: {loaded_model.feature_names_in_}\")\n",
        "\n",
        "# 2. Create a DataFrame with the correct column names\n",
        "# ** IMPORTANT: The names and order must match Step 1 exactly **\n",
        "new_material_df = pd.DataFrame([[5.0, -1.2, 100, 3]],\n",
        "                               columns=loaded_model.feature_names_in_)\n",
        "\n",
        "# 3. Make prediction (The warning will be gone)\n",
        "prediction = loaded_model.predict(new_material_df)\n",
        "print(f\"Predicted band gap: {prediction[0]:.4f}\")\n"
      ],
      "metadata": {
        "id": "nFj_G7y9n7EM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}