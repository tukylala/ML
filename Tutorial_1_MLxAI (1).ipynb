{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Virtual Tensile Tester\" using Machine Learning**\n"
      ],
      "metadata": {
        "id": "NdSw6ssZOVy9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Load the dataset**"
      ],
      "metadata": {
        "id": "KaZMza2oOqp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# 1. Load the dataset from a valid GitHub source\n",
        "# This dataset contains 312 steel alloys with their chemical composition and strength\n",
        "url = \"https://raw.githubusercontent.com/batiukmaks/Steel-Strength-Prediction/master/steel_strength.csv\"\n",
        "\n",
        "df = pd.read_csv(url)\n"
      ],
      "metadata": {
        "id": "-Ap3YwG0Ops9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Exploratory Data Analysis (EDA)**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IKcv2t4HPpsl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inspectthe data**"
      ],
      "metadata": {
        "id": "rdrcdp0nZHVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "IbaO8bh1OU_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "FL-BsTtaUUmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "x2ErgzqzT13f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Check for missing values\n",
        "print(\"\\n--- Missing Values ---\")\n",
        "print(df.isnull().sum())\n",
        "\n"
      ],
      "metadata": {
        "id": "9Xmeeh1641aH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'df' is the DataFrame loaded in Step 1\n",
        "\n",
        "print(\"Original dataset size:\", df.shape)\n",
        "\n",
        "# 1. Handle Missing Values in 'elongation'\n",
        "# We drop the rows where 'elongation' is NaN.\n",
        "df_clean = df.dropna(subset=['elongation'])\n",
        "\n",
        "print(\"Dataset size after dropping 9 missing 'elongation' rows:\", df_clean.shape)"
      ],
      "metadata": {
        "id": "pZvdioY77Hhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recheck for missing values\n",
        "print(\"\\n--- Missing Values ---\")\n",
        "print(df_clean.isnull().sum())"
      ],
      "metadata": {
        "id": "VW7ccUJ67KnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df_clean"
      ],
      "metadata": {
        "id": "8bXinCi57ctQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "C97ln_mv7fmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Basic statistics**\n",
        "\n"
      ],
      "metadata": {
        "id": "Gebzj_0ZY3Rd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()\n",
        "\n"
      ],
      "metadata": {
        "id": "EYYXpPDW5RqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure()\n",
        "sns.histplot(df['yield strength'], kde=True)\n",
        "plt.title('Distribution of Steel Yield Strength')\n",
        "plt.xlabel('Yield Strength (MPa)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gvAMEdG86JzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quiz!**\n",
        "\n",
        "How about distribution of Tensile Strength and Elongation?"
      ],
      "metadata": {
        "id": "VnGfTdTWZROa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M88nIoc2ZtD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gomQemYgZs5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.hist(figsize=(17,12))"
      ],
      "metadata": {
        "id": "MH_oFUIK0GOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,8))\n",
        "sns.boxplot(data=df.drop(columns=['yield strength', 'tensile strength', 'elongation']), showfliers=True, orient=\"h\")\n",
        "plt.title(\"Boxplot of columns\")"
      ],
      "metadata": {
        "id": "KoIHTYTz9Ahx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Correlation**"
      ],
      "metadata": {
        "id": "42hH5UcL9qTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 1. Create a numeric-only DataFrame by dropping the 'formula' column\n",
        "#    Alternatively, you can use df.corr(numeric_only=True) in newer pandas versions\n",
        "df_numeric = df.drop(columns=['formula'])\n",
        "\n",
        "# 2. Calculate the correlation matrix\n",
        "plt.figure(figsize=(12, 10))\n",
        "corr_matrix = df_numeric.corr()\n",
        "\n",
        "# 3. Plot the heatmap\n",
        "#    annot=True displays the actual correlation values in the cells\n",
        "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
        "plt.title('Feature Correlation Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zZ4s76tb5h-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Correlation with yield strength**\n"
      ],
      "metadata": {
        "id": "giUIILP_BWCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_y = df.drop(columns=['formula'])\n",
        "df_y.corrwith(df[\"yield strength\"])"
      ],
      "metadata": {
        "id": "V_Wced1O2T4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Data Splitting**"
      ],
      "metadata": {
        "id": "9-vLUlyeE5ig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **How to predict 'Yield Strength' (y) using the chemical elements (X)**\n",
        "\n",
        "**1. Define the Target (y)**\n",
        "\n",
        "**2. Define the Features (X)**\n",
        "\n",
        "We will drop the target column to keep only the ingredients\n"
      ],
      "metadata": {
        "id": "qXN69KIwQKaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the Target (y)\n",
        "y = df['yield strength']\n",
        "\n",
        "# 2. Define the Features (X) - SELECTING ONLY METALS\n",
        "# We create a list of only the metal columns\n",
        "metal_features = ['mn','si','cr', 'ni', 'mo', 'v', 'n', 'nb', 'co', 'w', 'al', 'ti']\n",
        "\n",
        "# Select only those columns from the dataframe\n",
        "X = df[metal_features]\n",
        "\n",
        "print(\"Selected only metal features:\")\n",
        "print(X.head())\n",
        "\n",
        "D = df.drop(columns=['formula','yield strength'])\n",
        "print(\"We have\", D.shape[0], \"steel samples.\")\n",
        "print(\"We are using\", D.shape[1], \"ingredients to predict strength.\")"
      ],
      "metadata": {
        "id": "Idugw_5OUa3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Train Model with RandomForestRegressor**"
      ],
      "metadata": {
        "id": "OB9rEWa_Scx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Split data into \"Study Guide\" (Train) and \"Final Exam\" (Test)\n",
        "# We replace ____ with 0.2 (which means 20% of data is for testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 2. Initialize the AI Brain\n",
        "model = RandomForestRegressor()\n",
        "\n",
        "# 3. Train the model (Fit)\n",
        "print(\"Training the ML model...\")\n",
        "# We replace ____ with X_train and y_train\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Training Complete!\")"
      ],
      "metadata": {
        "id": "_Hm_5kB4Sfgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Medel evaluation**"
      ],
      "metadata": {
        "id": "bAa9seLvLePe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import (\n",
        "    mean_absolute_error,\n",
        "    mean_squared_error,\n",
        "    r2_score,\n",
        "    median_absolute_error,\n",
        "    max_error,\n",
        "    explained_variance_score\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "# 1. Get predictions\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# 2. Calculate All Metrics\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "med_ae = median_absolute_error(y_test, predictions)\n",
        "max_err = max_error(y_test, predictions)\n",
        "\n",
        "# 3. Print the Report Card\n",
        "print(\"=== MODEL PERFORMANCE REPORT ===\")\n",
        "print(f\"1. R2 Score (Accuracy):          {r2:.4f}  \")\n",
        "print(f\"2. MAE (Average Error):          {mae:.2f} MPa \")\n",
        "print(f\"3. RMSE (Penalizes Big Errors):  {rmse:.2f} MPa \")\n",
        "print(f\"4. Median Error (Typical Error): {med_ae:.2f} MPa \")\n",
        "print(f\"5. Max Error (Worst Case):       {max_err:.2f} MPa \")\n",
        "print(\"================================\")"
      ],
      "metadata": {
        "id": "hFGuDkhHU_OW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Get predictions for BOTH sets\n",
        "train_preds = model.predict(X_train)\n",
        "test_preds = model.predict(X_test)\n",
        "\n",
        "plt.figure(figsize=(9, 9))\n",
        "\n",
        "# 2. Plot Training Data (Blue)\n",
        "# We use a lower 'alpha' (transparency) because there are usually many more training points\n",
        "plt.scatter(y_train, train_preds, color='skyblue', alpha=0.4, label='Training Set (Memorized)')\n",
        "\n",
        "# 3. Plot Test Data (Green)\n",
        "# These are the \"New\" alloys the model has never seen\n",
        "plt.scatter(y_test, test_preds, color='tomato', alpha=0.3, label='Test Set (New Data)')\n",
        "\n",
        "# 4. Draw the \"Perfect Prediction\" Line\n",
        "min_val = min(y.min(), train_preds.min()) # Find the lowest value in the whole dataset\n",
        "max_val = max(y.max(), train_preds.max()) # Find the highest value\n",
        "plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=3, label='Perfect Match')\n",
        "\n",
        "plt.title(\"Overfitting Check: Train vs. Test\")\n",
        "plt.xlabel(\"Actual Strength (MPa)\")\n",
        "plt.ylabel(\"Predicted Strength (MPa)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nYLsfU8gW15p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Model comparison**"
      ],
      "metadata": {
        "id": "3DL2NhX3KM3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Setup the 6 Contenders\n",
        "models = {\n",
        "    \"1. Linear Regression\": LinearRegression(),\n",
        "    \"2. K-Nearest Neighbors\": make_pipeline(StandardScaler(), KNeighborsRegressor()),\n",
        "    \"3. Random Forest\": RandomForestRegressor(random_state=42),\n",
        "    \"4. Gradient Boosting (sklearn)\": GradientBoostingRegressor(random_state=42),\n",
        "    \"5. Neural Network\": make_pipeline(StandardScaler(), MLPRegressor(hidden_layer_sizes=(100,50), max_iter=5000, random_state=42)),\n",
        "    \"6. XGBoost\": XGBRegressor(random_state=42)\n",
        "}\n",
        "\n",
        "# 2. Create a Scoreboard\n",
        "results = []\n",
        "\n",
        "print(\"Training 6 models... this might take a minute.\\n\")\n",
        "\n",
        "# 3. The Training Loop\n",
        "for name, model in models.items():\n",
        "    # Train\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict\n",
        "    preds = model.predict(X_test)\n",
        "\n",
        "    # Score\n",
        "    r2 = r2_score(y_test, preds)\n",
        "    mae = mean_absolute_error(y_test, preds)\n",
        "\n",
        "    # Save results\n",
        "    results.append({\"Model\": name, \"Accuracy (R2)\": r2, \"MAE (MPa)\": mae})\n",
        "\n",
        "# 4. Display the Final Leaderboard\n",
        "leaderboard = pd.DataFrame(results).sort_values(by=\"Accuracy (R2)\", ascending=False)\n",
        "print(leaderboard.to_string(index=False, float_format='{:.4f}'.format))"
      ],
      "metadata": {
        "id": "i_eibi-sZhrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# 1. Identify the Winner\n",
        "# Grab the name of the model in the first row (since it's sorted by R2 descending)\n",
        "best_model_name = leaderboard.iloc[0]['Model']\n",
        "print(f\"\\nüèÜ The Best Model is: {best_model_name}\")\n",
        "\n",
        "# 2. Retrieve the Trained Object\n",
        "# Look up the actual model object from your original 'models' dictionary\n",
        "best_model = models[best_model_name]\n",
        "\n",
        "# 3. Save to Disk\n",
        "filename = 'best_concrete_model_ST.pkl'\n",
        "joblib.dump(best_model, filename)\n",
        "\n",
        "print(f\"‚úÖ Successfully saved {best_model_name} to '{filename}'\")"
      ],
      "metadata": {
        "id": "IWvGUywHQBSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. Feature importance**"
      ],
      "metadata": {
        "id": "csEp20nyM1p7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Load the Model\n",
        "# Make sure this matches the filename you saved earlier\n",
        "model = joblib.load('best_concrete_model_ST.pkl')\n",
        "print(f\"Loaded model type: {type(model)}\")\n",
        "\n",
        "# 1. Get the \"Importance\" numbers from the model\n",
        "importances = model.feature_importances_\n",
        "\n",
        "# 2. Create a DataFrame to display them nicely\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Ingredient': X.columns,\n",
        "    'Importance': importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# 3. Plot the Top 10 Ingredients\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_importance_df['Ingredient'][:10], feature_importance_df['Importance'][:10], color='teal')\n",
        "plt.xlabel(\"Importance Score\")\n",
        "plt.title(\"Which Ingredients Drive Strength?\")\n",
        "plt.gca().invert_yaxis() # Put the most important at the top\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "paXGVuztj_bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9. DATA Prediction**"
      ],
      "metadata": {
        "id": "GkZGlBsB3fZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "# 1. Load the Model (You likely already did this)\n",
        "model = joblib.load('best_concrete_model_ST.pkl')\n",
        "\n",
        "# 2. Define your features exactly as they were used in training\n",
        "metal_features = ['mn', 'si', 'cr', 'ni', 'mo', 'v', 'n', 'nb', 'co', 'w', 'al', 'ti']\n",
        "\n",
        "# 3. Create the single data point\n",
        "# Replace these values with the actual numbers you want to predict\n",
        "single_data_dict = {\n",
        "    'mn': 0.5,\n",
        "    'si': 4.5,\n",
        "    'cr': 3.0,\n",
        "    'ni': 16.0,\n",
        "    'mo': 4.0,\n",
        "    'v':  3.0,\n",
        "    'n':  0.5,\n",
        "    'nb': 2.0,\n",
        "    'co': 3.0,\n",
        "    'w':  1.0,\n",
        "    'al': 2.0,\n",
        "    'ti': 1.0\n",
        "}\n",
        "\n",
        "# 4. Convert to a DataFrame\n",
        "# We wrap the dictionary in a list [ ... ] to make it a single row\n",
        "X_single = pd.DataFrame([single_data_dict])\n",
        "\n",
        "# Ensure columns are in the exact same order as training\n",
        "X_single = X_single[metal_features]\n",
        "\n",
        "# 5. Make the Prediction\n",
        "prediction = model.predict(X_single)\n",
        "\n",
        "# 6. Output the result\n",
        "print(f\"Input Features:\\n{X_single}\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"Predicted Value (y): {prediction[0]:.4f}\")"
      ],
      "metadata": {
        "id": "tQm4kk402h86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10. Parameter Opimization**"
      ],
      "metadata": {
        "id": "BXYOt_EAOieY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Define \"Unexplored Territory\"\n",
        "# We allow the ingredients to go 50% higher than the maximum we've ever tested\n",
        "# range_extension = 1.5 means \"150% of the max value\"\n",
        "extended_max = X.max()\n",
        "extended_min = X.min() # Keep min at 0 (can't have negative ingredients)\n",
        "\n",
        "# 2. Generate 10,000 \"Extreme\" Alloys\n",
        "num_samples = 10000\n",
        "extreme_alloys = pd.DataFrame(\n",
        "    np.random.uniform(extended_min, extended_max, size=(num_samples, len(X.columns))),\n",
        "    columns=X.columns\n",
        ")\n",
        "\n",
        "# 3. Predict using a model capable of extrapolation\n",
        "# Note: Random Forest generally CANNOT predict higher than training max.\n",
        "# We will use Linear Regression here just to demonstrate \"Unbounded\" prediction,\n",
        "# OR we rely on the Random Forest finding a better COMBINATION within the bounds.\n",
        "# Let's stick to our best model (likely Gradient Boosting or RF) and see if it finds a peak.\n",
        "predicted_extreme = model.predict(extreme_alloys)\n",
        "\n",
        "# 4. Find the Winner\n",
        "best_idx = np.argmax(predicted_extreme)\n",
        "best_alloy = extreme_alloys.iloc[best_idx]\n",
        "best_strength = predicted_extreme[best_idx]\n",
        "\n",
        "print(f\"=== THE EXTREME ALLOY ===\")\n",
        "print(f\"Max Strength in Training Data: {y.max():.2f} MPa\")\n",
        "print(f\"Predicted Extreme Strength:    {best_strength:.2f} MPa\")\n",
        "\n",
        "if best_strength > y.max():\n",
        "    print(\"üöÄ SUCCESS: We found a theoretical material stronger than anything existing!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è LIMIT REACHED: The model thinks we've already hit the physical limit of steel.\")\n",
        "\n",
        "# 5. Visualize \"The Edge of Knowledge\"\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(predicted_extreme, bins=30, alpha=0.5, label='AI Predictions (Unknown)', color='Orange')\n",
        "plt.hist(y, bins=30, alpha=0.7, label='Real Data (Known)', color='blue')\n",
        "\n",
        "plt.axvline(y.max(), color='red', linestyle='--', label='Current Record')\n",
        "plt.legend()\n",
        "plt.title(\"Did we break the World Record?\")\n",
        "plt.xlabel(\"Yield Strength (MPa)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HxDLs8zisbzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Show the Top 5 Candidates\n",
        "# Create a temporary table combining the Recipe with the Strength\n",
        "results_table = extreme_alloys.copy()\n",
        "results_table['Predicted Strength (MPa)'] = predicted_extreme\n",
        "\n",
        "# Sort by Strength (Highest to Lowest) and take the top 5\n",
        "top_5 = results_table.sort_values(by='Predicted Strength (MPa)', ascending=False).head(5)\n",
        "\n",
        "print(\"\\n=== TOP 5 CANDIDATE ALLOYS ===\")\n",
        "# We transpose (.T) the table so it's easier to read the chemical ingredients\n",
        "print(top_5.T)"
      ],
      "metadata": {
        "id": "8kKlGvNktez4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}