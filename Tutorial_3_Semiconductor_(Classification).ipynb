{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Materials Analysis**"
      ],
      "metadata": {
        "id": "n3uup_lwCCNk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Data Loading**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nDzVrGDaMf-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# --- 1. Download & Load Data ---\n",
        "# Download dataset\n",
        "path = kagglehub.dataset_download(\"allanwandia/material-science\")\n",
        "\n",
        "# Find the CSV file in the download folder\n",
        "csv_files = [f for f in os.listdir(path) if f.endswith('.csv')]\n",
        "full_path = os.path.join(path, csv_files[0])\n",
        "\n",
        "df = pd.read_csv(full_path)"
      ],
      "metadata": {
        "id": "QgVmOtC5X-qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Checking data information**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "btEWvsH1NFGx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Basic command for checking data information\n",
        "\n",
        "```\n",
        "df.info()\n",
        "df.head()\n",
        "df.tail()\n",
        "df.describe()\n",
        "df.columns"
      ],
      "metadata": {
        "id": "tRwo3Wc-NWII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "n9er17sZQnoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check for missing values"
      ],
      "metadata": {
        "id": "FJDcaYjpNww9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print('Missing values in each column:')\n",
        "print(df.isnull().sum())\n",
        "\n"
      ],
      "metadata": {
        "id": "QP1c4HEbNvMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If any numeric columns have missing values, fill them with the median"
      ],
      "metadata": {
        "id": "uAOklIKmQdF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic cleaning: if any numeric columns have missing values, fill them with the median\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "for col in numeric_cols:\n",
        "    if df[col].isnull().sum() > 0:\n",
        "        median_val = df[col].median()\n",
        "        df[col].fillna(median_val, inplace=True)\n",
        "\n",
        "# For any categorical columns with missing values, fill with 'Unknown'\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "for col in categorical_cols:\n",
        "    if df[col].isnull().sum() > 0:\n",
        "        df[col].fillna('Unknown', inplace=True)\n",
        "\n",
        "# Final shape after cleaning\n",
        "print('Data shape after cleaning:', df.shape)"
      ],
      "metadata": {
        "id": "i8Xn24eoQVlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "AgUnvwG-i27h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "jI6B7iRFYx3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "lRA5bF25QzgZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Count Plot for boolean columns**"
      ],
      "metadata": {
        "id": "zEkJzbaPRmFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Count Plot for boolean columns\n",
        "bool_cols = df.select_dtypes(include=['bool']).columns\n",
        "for col in bool_cols:\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.countplot(x=df[col])\n",
        "    plt.title(f'Count Plot of {col}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Count')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "KETwLxoXRmgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(numeric_df)\n",
        "plt.suptitle('Pair Plot for Numeric Features', y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jzRTGwLLD4o-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Prediction Modeling**"
      ],
      "metadata": {
        "id": "0pGLD_keZMwP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define target variable and select feature set\n"
      ],
      "metadata": {
        "id": "AN9u1HcXT284"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['is_semiconductor'].head(5)"
      ],
      "metadata": {
        "id": "Ch1H3mFRSC3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target: Convert True/False to 1/0\n",
        "\n",
        "df_class = df.copy()\n",
        "df_class['target'] = df_class['is_semiconductor'].astype(int)\n",
        "df_class['target'].head(5)"
      ],
      "metadata": {
        "id": "y0cRJ17EZwep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Features: Physical properties"
      ],
      "metadata": {
        "id": "zduo_bXiUK59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Features: Physical properties\n",
        "features = ['density', 'formation_energy_per_atom', 'volume', 'n_elements']\n",
        "X = df_class[features]\n",
        "y = df_class['target']"
      ],
      "metadata": {
        "id": "CbJC64RGUPgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split Data"
      ],
      "metadata": {
        "id": "O7gf4LG6URop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "d4iHwliTUTyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "Vlzbd6YzUWYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Model ---\n",
        "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Classifier trained on {len(X_train)} materials.\")"
      ],
      "metadata": {
        "id": "eOVrNxQOUdRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Model Evaluation**"
      ],
      "metadata": {
        "id": "Ma5N6L-HVHET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate ---\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {acc*100:.2f}%\")"
      ],
      "metadata": {
        "id": "OLVBLHRWaEz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization (Confusion Matrix) ---\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Metal', 'Semiconductor'],\n",
        "            yticklabels=['Metal', 'Semiconductor'])\n",
        "plt.ylabel('Actual Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "XYsm6jIYaQy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Model comparison**"
      ],
      "metadata": {
        "id": "DQlHf6ZtWIPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n",
        "\n",
        "# ... (Imports and Data Split code remains the same) ...\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "# --- TRACKING VARIABLES ---\n",
        "best_model = None\n",
        "best_score = 0.0\n",
        "best_name = \"\"\n",
        "\n",
        "print(f\"{'Model Name':<25} | {'Accuracy':<10}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "for name, model in models.items():\n",
        "\n",
        "    # Train\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"{name:<25} | {acc:.4f}\")\n",
        "\n",
        "    # --- CHECK IF THIS IS THE NEW CHAMPION ---\n",
        "    if acc > best_score:\n",
        "        best_score = acc\n",
        "        best_model = model\n",
        "        best_name = name\n",
        "\n",
        "print(\"-\" * 40)\n",
        "print(f\"üèÜ The Winner is: {best_name} with {best_score:.4f} accuracy!\")\n",
        "\n",
        "# --- SAVE THE CHAMPION ---\n",
        "joblib.dump(best_model, 'best_materials_model.pkl')\n",
        "print(f\"Saved {best_name} to 'best_materials_model.pkl'\")"
      ],
      "metadata": {
        "id": "m5WOB2RYkkKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Feature importances**"
      ],
      "metadata": {
        "id": "YOvd0gW8VlFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Get the importance scores\n",
        "# Note: This only works for Random Forest / Gradient Boosting / Decision Trees\n",
        "importances = best_model.feature_importances_\n",
        "\n",
        "# 2. Organize them into a clean table\n",
        "# 'features' is the list you defined at the very beginning:\n",
        "# ['density', 'formation_energy_per_atom', 'volume', 'n_elements']\n",
        "feature_table = pd.DataFrame({\n",
        "    'Feature': features,\n",
        "    'Importance': importances\n",
        "})\n",
        "\n",
        "# 3. Sort by importance (Highest on top)\n",
        "feature_table = feature_table.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(feature_table)\n",
        "\n",
        "# 4. (Optional) Visualize it!\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.barh(feature_table['Feature'], feature_table['Importance'], color='cornflowerblue')\n",
        "plt.xlabel('Importance Score (0 to 1)')\n",
        "plt.title('What mattered most to the model?')\n",
        "plt.gca().invert_yaxis() # Put the most important at the top\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NgZTUfobp4wU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Load the best model**"
      ],
      "metadata": {
        "id": "wau3rFXOWgi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "# 1. LOAD the model\n",
        "loaded_model = joblib.load('best_materials_model.pkl')\n",
        "\n",
        "# 2. PREPARE INPUT\n",
        "# Define the raw values\n",
        "['density' 'formation_energy_per_atom' 'volume' 'n_elements']\n",
        "\n",
        "raw_data = [[5.0, -1.2, 100, 3]]\n",
        "\n",
        "# FIX: Create a DataFrame using the feature names stored in the model\n",
        "# This tells sklearn exactly which value corresponds to which feature\n",
        "new_material_df = pd.DataFrame(raw_data, columns=loaded_model.feature_names_in_)\n",
        "\n",
        "# 3. PREDICT (Warning will be gone)\n",
        "prediction = loaded_model.predict(new_material_df)\n",
        "\n",
        "print(\"Prediction:\",\n",
        "      \"üü¢ Semiconductor\" if prediction[0] == 1 else \"üî¥ Not Semiconductor\")\n"
      ],
      "metadata": {
        "id": "nFj_G7y9n7EM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
